# 1. SCALABILITY
将Scalability的需求分为两种：
* Data Scalability： 单台机器的容量不足以(经济的承载)所有资料，需要分散，如：NoSQL
* Computing Scalability：单台机器的运算能力不能(经济的)及时完成计算，需要分散


在采用分散式架构时，注定要接收一些牺牲：
* 牺牲效率： 网路延迟与节点间的协调，都会降低效率
* 牺牲AP弹性：有些在单机上能执行的运算，无法轻易的在分散式环境中完成
* 牺牲维护运维能力：分布式架构的问题很难重现与追踪。

与单机系统一样，也有一些系统设计上的 tradeoffs
* **CPU使用效率优化** 或者  **是IO效率优化**
* **读取优化** 或者 **写入优化**
* **Throughput优化** 或者 **Latency优化**
* **资料一致性** 或者 **资料可得性**

选择不用的 **tradeoff** 就会有不同的系统架构。

# 2. 分散式系统的面向
分散式系统都是特化的，而不是通用的，所以不同的设计决策就会衍射处不同用途的系统。
分散式系统分为两种：**资料系统** 和 **运算系统**
对于资料系统来说，主要的技术手段是 partition 和 replication,再搭配不同的读写方式就会由很多不同的变化，几个设计决策包括：
* 资料切割
* 读写分工
* 处理颗粒度
* 交易处理
* 资料复制
* 可用性保证
* 错误回复
 
 # 3. PARTIOTION
 分散式资料系统的两个问题根源是：**partition** 和 **replication**。 当资料放不进一台机器，或是对资料的运算太过耗时，单台机器无法负荷时，就是 **partition**.那么如何切分资料？
 * Round_Robin:资料轮流进入多台机器，好处是 load balance，坏处四不适合有 session 或 资料相依性(nedd join)的应用。变型时可以用 thread pool，每个机器固定配几个 thread，这可以避免某个运算耗时过久，而挡道后面运算的问题。
 * Range: 事先设定好每台机器的防守范围，
 * Hash:用 Hash来决定资料要再哪台机器上，简单的Hash时取余数，但是取余数再新增机器时会有资料迁移的问题，所以现在大家比较宠用 Consistent Hashing 来避免这个问题。
 * Manual：手动建一个对照表。

# 4.为何有些时候不把Query洒到所有机器上平行处理？
效能降低的风险：所有机器都回传资料后才能完成运算，所以运算时间是 Max(各台机器的处理时间)，机器越多，发生异常的机会越高，导致运算延迟。

# 5. 资料切割的 METADATA 管理
现在有好几台机器，都必须follow同一套资料的切割方式，这个切割方式存在 metadata中，这个 metadata如果不见，那之后的资料就不知道该写入哪一台。
一个简单的方式就是 **一台机器**专门管理这些 metadata(meta server, config sercer),但这明显是一个 单点问题。

# 6. REPLCATION
**资料复制**是维持 可用性的方法，因为资料复制好几份到不同机器，所以只要有一台机器还在，资料就拿得到。但是只要有资料复制，就一定会有 **延迟** 的状况，也就是在 资料复制完成前，多台机器的资料是不一致的。
有的系统对资料的一致性读很高要求，会采用 **同步复制**，要复制完成后资料才会读取，但这样很慢。
折中 **Quorun**,可以控制要 write-efficient 还是 read-efficient, 然后牺牲另一个 operation的效率来换资料的一致性。
另外呢，每更新一笔资料就发一次副本更新是很没有效率的，通常要累计一些更新或隔一段时间才会 batch update。
常见的复制是有 **三个副本**，除了原本的资料之外，同一个 rack 或 data center一个副本，另一个rack 或 data center 再一个。
那么副本允不允许写入呢？多数资料系统是不允许的，也就是说，副本纯粹只是增加 read concurrency/efficiency/availabilty.同样是副本，同时只有一个 master 副本 负责写入，其他的 salve 副本只负责 read request.



