{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#nn.moduleList-和-Sequential由来和用法\" data-toc-modified-id=\"nn.moduleList-和-Sequential由来和用法-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>nn.moduleList 和 Sequential由来和用法</a></span><ul class=\"toc-item\"><li><span><a href=\"#nn.Sequential()对象\" data-toc-modified-id=\"nn.Sequential()对象-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>nn.Sequential()对象</a></span><ul class=\"toc-item\"><li><span><a href=\"#模型建立的方法\" data-toc-modified-id=\"模型建立的方法-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>模型建立的方法</a></span></li><li><span><a href=\"#检查以及调用模型\" data-toc-modified-id=\"检查以及调用模型-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>检查以及调用模型</a></span></li><li><span><a href=\"#根据名字或者序号提取Module对象\" data-toc-modified-id=\"根据名字或者序号提取Module对象-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>根据名字或者序号提取Module对象</a></span></li></ul></li><li><span><a href=\"#nn.ModuleList()对象\" data-toc-modified-id=\"nn.ModuleList()对象-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>nn.ModuleList()对象</a></span><ul class=\"toc-item\"><li><span><a href=\"#extend和append方法\" data-toc-modified-id=\"extend和append方法-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>extend和append方法</a></span></li><li><span><a href=\"#建立以及使用方法\" data-toc-modified-id=\"建立以及使用方法-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>建立以及使用方法</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.moduleList 和 Sequential由来和用法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于cnn前馈神经网络如果前馈一次写一个forward函数会有些麻烦，在此就有两种简化方式，<span class=\"burk\">**ModuleLis**</span>t和<span class=\"burk\">**Sequential**</span>。其中Sequential是一个特殊的module，它包含几个子Module，<span class=\"girk\">前向传播时会将输入一层接一层的传递下去</span>。ModuleList也是一个特殊的module，可以包含几个子module，可以像用list一样使用它，但<span class=\"girk\">不能直接把输入传给ModuleList</span>。下面举例说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential()对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立nn.Sequential()对象，必须小心确保一个块的输出大小与下一个块的输入大小匹配。基本上，它的行为就像一个nn.Module。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型建立的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <span class=\"mark\">第一种写法</span>： \n",
    "nn.Sequential()对象.add_module(层名，层class的实例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net1 = nn.Sequential()\n",
    "net1.add_module('conv',nn.Conv2d(3,3,3))\n",
    "net1.add_module('batchnorm',nn.BatchNorm2d(3))\n",
    "net1.add_module('activation_layer',nn.ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <span class=\"mark\">第二种写法</span>(*多个层class的实例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = nn.Sequential(\n",
    "nn.Conv2d(3,3,3),\n",
    "nn.BatchNorm2d(3),\n",
    "nn.ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <span class=\"mark\">第三种写法</span> ： nn.Sequential(OrderDict([*多个(层名，层class的实例）]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "net3 = nn.Sequential(OrderedDict([\n",
    "    ('conv',nn.Conv2d(3,3,3)),\n",
    "    ('batchnorm',nn.BatchNorm2d(3)),\n",
    "    ('activation_layer',nn.ReLU())\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查以及调用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1:  Sequential(\n",
      "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation_layer): ReLU()\n",
      ")\n",
      "net2:  Sequential(\n",
      "  (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n",
      "net3:  Sequential(\n",
      "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation_layer): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('net1: ',net1)\n",
    "print('net2: ',net2)\n",
    "print('net3: ',net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据名字或者序号提取Module对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)),\n",
       " Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)),\n",
       " Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.conv,net2[0],net3.conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ModuleList()对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为何有他？**\n",
    "写一个module然后就写foreword函数很麻烦，所以就有了这两个。它被<span class=\"burk\">设计用来存储任意数量</span>的nn.module\n",
    "\n",
    "**什么时候用？**\n",
    "\n",
    "如果在构造函数__init__中用到list、tuple、dict等对象时，一定要思考是否应该用ModuleList或ParameterList代替。\n",
    "\n",
    "如果你想设计一个神经网络的层数作为输入传递\n",
    "\n",
    "**和List之间区别**\n",
    "\n",
    "ModuleList是Module的子类，当在Module中使用它的时候，就能自动识别为子module。\n",
    "当添加 nn.ModuleList 作为 nn.Module 对象的一个成员时（即当我们添加模块到我们的网络时），所有 nn.ModuleList 内部的 nn.Module 的 parameter 也被添加作为 我们的网络的 parameter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule,self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10,10) for i in range(10)])\n",
    "    def forward(self,x):\n",
    "        # ModuleList can act as an iterable, or be indexed\n",
    "        for i,l in enumerate(self.linears):\n",
    "            x = self.linears[i//2](x) + l(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (5): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (7): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (9): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MyModule()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extend和append方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"burk\">nn.moduleList定义对象后，有extend和append方法</span>，用法和python中一样，<span class=\"burk\">extend是添加另一个modulelist</span>  <span class=\"burk\">append是添加另一个module</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "  def __init__(self, input_size, num_layers, layers_size, output_size):\n",
    "     super(LinearNet, self).__init__()\n",
    " \n",
    "     self.linears = nn.ModuleList([nn.Linear(input_size, layers_size)])\n",
    "     self.linears.extend([nn.Linear(layers_size, layers_size) for i in range(1, self.num_layers-1)])\n",
    "     self.linears.append(nn.Linear(layers_size, output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立以及使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellist = nn.ModuleList"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
